{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = os.getcwd() + '/data/SDALLE_raw/'\n",
    "OUTPUT_PATH = os.getcwd() + '/data/SDALLE_processed_data/'\n",
    "\n",
    "SAMPLE_RATE = 148.1481\n",
    "WINDOW_SECONDS = 4\n",
    "HOP_SECONDS = 2\n",
    "FRAME_SIZE = int(SAMPLE_RATE * WINDOW_SECONDS)\n",
    "HOP_SIZE = int(SAMPLE_RATE * HOP_SECONDS)\n",
    "\n",
    "UTENTI = range(1, 10)\n",
    "ATTIVITA = ['Jogging', 'Stairs_up', 'Stairs_down', 'Walking']\n",
    "\n",
    "SENSORS = [\n",
    "    'Rectus_Femoris_left', 'Rectus_Femoris_right', 'Vastus_Medialis_left',\n",
    "    'Vastus_Medialis_right', 'Vastus_Lateralis_Left', 'Vastus_Lateralis_right',\n",
    "    'Semitendinosus_left', 'Semitendinosus_right'\n",
    "]\n",
    "\n",
    "MODALITIES = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trial_data(file_path):\n",
    "    column_names = [f\"{modality}_{sensor}\" for sensor in SENSORS for modality in MODALITIES]\n",
    "    \n",
    "    try:\n",
    "        # 2. Leggi i dati saltando le 8 righe di header, senza usare l'header del file\n",
    "        df = pd.read_csv(file_path, header=None, skiprows=8, on_bad_lines='skip')\n",
    "        \n",
    "        # Se pandas legge colonne extra a causa di virgole finali, tronca al numero atteso (56)\n",
    "        if df.shape[1] > len(column_names):\n",
    "            df = df.iloc[:, :len(column_names)]\n",
    "\n",
    "        # 3. Assegna i nomi delle colonne generati\n",
    "        df.columns = column_names\n",
    "        df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Errore caricando o processando {file_path}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65822801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(data, frame_size, hop_size):\n",
    "    if len(data) < frame_size: return pd.DataFrame()\n",
    "    r = np.arange(len(data)); s = r[::hop_size]\n",
    "    window_dentro = s[s + frame_size <= len(data)]\n",
    "    z = list(zip(window_dentro, window_dentro + frame_size))\n",
    "    g = lambda indices: data.iloc[indices[0]:indices[1]]\n",
    "    if not z: return pd.DataFrame()\n",
    "    return pd.concat(map(g, z), keys=range(len(z)))\n",
    "\n",
    "def calc_over_in_below_mean(df, cols, perc = 0.01):\n",
    "    result_dict = {}\n",
    "\n",
    "    df_mean = df[cols].mean()\n",
    "    df_lim_inf = df_mean - df_mean.abs() * perc\n",
    "    df_lim_sup = df_mean + df_mean.abs() * perc\n",
    "\n",
    "    for col in cols:\n",
    "        result_dict[format_colname(col, \"OverMean\")] = (df[col] > df_lim_sup[col]).sum()\n",
    "        result_dict[format_colname(col, \"InMean\")] = ((df[col] >= df_lim_inf[col]) & (df[col] <= df_lim_sup[col])).sum()\n",
    "        result_dict[format_colname(col, \"BelowMean\") ] = (df[col] < df_lim_inf[col]).sum()\n",
    "\n",
    "    return pd.DataFrame([result_dict])\n",
    "\n",
    "def calculate_energy(series):\n",
    "    fft_result = np.fft.fft(series.values)\n",
    "    power_spectrum = np.abs(fft_result)**2 / len(series)\n",
    "    return np.sum(power_spectrum)\n",
    "\n",
    "def format_colname(col, stat):\n",
    "    if col[0] == 'g' and len(col) < 3:\n",
    "        col = col[1:]\n",
    "        if \"_\" in col:\n",
    "            first, rest = col.split(\"_\", 1)\n",
    "            if len(first) == 1:\n",
    "                return f\"Gyro{first.upper()}{stat}_{rest}\"\n",
    "            elif first == \"GyroMagnitude\":\n",
    "                return f\"{first}{stat}_{rest}\"\n",
    "            else:\n",
    "                return f\"{first}{stat}_{rest}\"\n",
    "        else:\n",
    "            if len(col) == 1:\n",
    "                return f\"Gyro{col.upper()}{stat}\"\n",
    "            elif col == \"GyroMagnitude\":\n",
    "                return f\"{col}{stat}\"\n",
    "            else:\n",
    "                return f\"{col}{stat}\"\n",
    "    else:\n",
    "        if \"_\" in col:\n",
    "            first, rest = col.split(\"_\", 1)\n",
    "            if len(first) == 1:\n",
    "                return f\"Acc{first.upper()}{stat}_{rest}\"\n",
    "            elif first == \"AccMagnitude\":\n",
    "                return f\"{first}{stat}_{rest}\"\n",
    "            else:\n",
    "                return f\"{first}{stat}_{rest}\"\n",
    "        else:\n",
    "            if len(col) == 1:\n",
    "                return f\"Acc{col.upper()}{stat}\"\n",
    "            elif col == \"AccMagnitude\":\n",
    "                return f\"{col}{stat}\"\n",
    "            else:\n",
    "                return f\"{col}{stat}\"\n",
    "\n",
    "def calculate_features(df, feature_cols, energy_cols):\n",
    "    df_windowed = get_frames(df, FRAME_SIZE, HOP_SIZE)\n",
    "    grouped = df_windowed.groupby(level=0)\n",
    "    \n",
    "    all_stat_features = []\n",
    "    all_stat_features.append(grouped[feature_cols].mean().add_suffix('Mean'))\n",
    "    all_stat_features.append(grouped[feature_cols].std().add_suffix('Std'))\n",
    "    all_stat_features.append(grouped[feature_cols].min().add_suffix('Min'))\n",
    "    all_stat_features.append(grouped[feature_cols].max().add_suffix('Max'))\n",
    "\n",
    "    df_mean = grouped[feature_cols].mean()\n",
    "    df_mean.columns = [format_colname(col, \"Mean\") for col in feature_cols]\n",
    "\n",
    "    df_std = grouped[feature_cols].std()\n",
    "    df_std.columns = [format_colname(col, \"Std\") for col in feature_cols]\n",
    "\n",
    "    df_min = grouped[feature_cols].min()\n",
    "    df_min.columns = [format_colname(col, \"Min\") for col in feature_cols]\n",
    "\n",
    "    df_max = grouped[feature_cols].max()\n",
    "    df_max.columns = [format_colname(col, \"Max\") for col in feature_cols]\n",
    "\n",
    "    all_features = pd.concat(all_stat_features, axis=1)\n",
    "\n",
    "    df_oib_mean = grouped.apply(lambda x: calc_over_in_below_mean(x, feature_cols))\n",
    "    df_oib_mean = df_oib_mean.reset_index(level=1, drop=True)\n",
    "\n",
    "    energy_features_list = []\n",
    "    for col in energy_cols:\n",
    "        energy_series = grouped[col].apply(calculate_energy)\n",
    "        energy_series.name = format_colname(col, \"Energy\")\n",
    "        energy_features_list.append(energy_series)\n",
    "    df_energy = pd.concat(energy_features_list, axis=1)\n",
    "\n",
    "    all_features = pd.concat([df_mean, df_std, df_min, df_max, df_oib_mean, df_energy], axis=1)\n",
    "\n",
    "    return all_features.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "for utente_id in tqdm(UTENTI, desc=\"Processing Users\"):\n",
    "    user_single_sensor_features = []\n",
    "    user_combined_sensor_features = []\n",
    "\n",
    "    for attivita in ATTIVITA:\n",
    "        activity_path = os.path.join(BASE_DATA_PATH, f\"Subject_{utente_id}\", attivita)\n",
    "        trial_files = glob.glob(os.path.join(activity_path, \"Trial_*.csv\"))\n",
    "\n",
    "        for trial_file in trial_files:\n",
    "            # Carica i dati del trial, che contengono tutti i sensori\n",
    "            df_trial = load_trial_data(trial_file)\n",
    "            if df_trial.empty:\n",
    "                continue\n",
    "\n",
    "            # --- A) Processamento per \"COMBINED\" (tutti i sensori insieme) ---\n",
    "            acc_mag_cols_combined = []\n",
    "            for sensor_name in SENSORS:\n",
    "                x_col, y_col, z_col = f\"AccX_{sensor_name}\", f\"AccY_{sensor_name}\", f\"AccZ_{sensor_name}\"\n",
    "                mag_col = f\"AccMagnitude_{sensor_name}\"\n",
    "                df_trial[mag_col] = np.sqrt(np.square(df_trial[[x_col, y_col, z_col]]).sum(axis=1))\n",
    "                acc_mag_cols_combined.append(mag_col)\n",
    "\n",
    "            gyro_mag_cols_combined = []\n",
    "            for sensor_name in SENSORS:\n",
    "                gx_col, gy_col, gz_col = f\"GyroX_{sensor_name}\", f\"GyroY_{sensor_name}\", f\"GyroZ_{sensor_name}\"\n",
    "                gyro_mag_col = f\"GyroMagnitude_{sensor_name}\"\n",
    "                df_trial[gyro_mag_col] = np.sqrt(np.square(df_trial[[gx_col, gy_col, gz_col]]).sum(axis=1))\n",
    "                gyro_mag_cols_combined.append(gyro_mag_col)\n",
    "\n",
    "            # ACC\n",
    "            acc_cols_all_sensors = [f\"Acc{ax}_{s}\" for s in SENSORS for ax in ['X', 'Y', 'Z']]\n",
    "            # GYRO\n",
    "            gyro_cols_all_sensors = [f\"Gyro{ax}_{s}\" for s in SENSORS for ax in ['X', 'Y', 'Z']]\n",
    "\n",
    "            # Combina tutto\n",
    "            feature_cols_combined = acc_cols_all_sensors + gyro_cols_all_sensors + acc_mag_cols_combined + gyro_mag_cols_combined\n",
    "            energy_cols_combined = acc_mag_cols_combined + gyro_mag_cols_combined\n",
    "\n",
    "            # Calcola feature\n",
    "            df_features_combined = calculate_features(df_trial, feature_cols_combined, energy_cols=energy_cols_combined)\n",
    "\n",
    "            if not df_features_combined.empty:\n",
    "                df_features_combined['Userid'] = utente_id\n",
    "                df_features_combined['Activity'] = attivita\n",
    "                df_features_combined['position'] = 'all position' # Usa il nome completo come 'position'\n",
    "                user_combined_sensor_features.append(df_features_combined)\n",
    "\n",
    "            # --- B) Processamento per \"SINGLE\" (ogni sensore individualmente) ---\n",
    "            for sensor_name in SENSORS:\n",
    "                # Seleziona le colonne per un singolo sensore e rinominale in modo generico\n",
    "                single_sensor_cols = {\n",
    "                    f\"AccX_{sensor_name}\": 'x',\n",
    "                    f\"AccY_{sensor_name}\": 'y',\n",
    "                    f\"AccZ_{sensor_name}\": 'z',\n",
    "                    f\"GyroX_{sensor_name}\": 'gx',\n",
    "                    f\"GyroY_{sensor_name}\": 'gy',\n",
    "                    f\"GyroZ_{sensor_name}\": 'gz'\n",
    "                }\n",
    "\n",
    "                df_single_sensor = df_trial[list(single_sensor_cols.keys())].copy()\n",
    "                df_single_sensor.rename(columns=single_sensor_cols, inplace=True)\n",
    "\n",
    "                df_single_sensor['AccMagnitude'] = np.sqrt(np.square(df_single_sensor[['x', 'y', 'z']]).sum(axis=1))\n",
    "                df_single_sensor['GyroMagnitude'] = np.sqrt(np.square(df_single_sensor[['gx', 'gy', 'gz']]).sum(axis=1))\n",
    "                df_features_single = calculate_features(df_single_sensor, ['x', 'y', 'z', 'gx', 'gy', 'gz', 'AccMagnitude', 'GyroMagnitude'],['AccMagnitude', 'GyroMagnitude'])\n",
    "                \n",
    "                if not df_features_single.empty:\n",
    "                    df_features_single['Userid'] = utente_id\n",
    "                    df_features_single['Activity'] = attivita\n",
    "                    df_features_single['position'] = sensor_name # Usa il nome completo come 'position'\n",
    "                    user_single_sensor_features.append(df_features_single)\n",
    "\n",
    "    # --- SALVATAGGIO DEI FILE PER L'UTENTE ---\n",
    "    # Salva il file per i sensori singoli\n",
    "    if user_single_sensor_features:\n",
    "        df_final_single = pd.concat(user_single_sensor_features, ignore_index=True)\n",
    "        output_filename_single = f\"{OUTPUT_PATH}/grouped_data_User{utente_id}.csv\"\n",
    "        df_final_single.to_csv(output_filename_single, index=False)\n",
    "\n",
    "    # Salva il file per i sensori combinati\n",
    "    if user_combined_sensor_features:\n",
    "        df_final_combined = pd.concat(user_combined_sensor_features, ignore_index=True)\n",
    "        output_filename_combined = f\"{OUTPUT_PATH}/grouped_data_User{utente_id}_combined.csv\"\n",
    "        df_final_combined.to_csv(output_filename_combined, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
