{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ddc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = os.getcwd() + '/data/selfBACK_raw'\n",
    "OUTPUT_PATH = os.getcwd() + '/data/selfBACK_processed_data'\n",
    "\n",
    "SAMPLE_RATE = 100   # Hz\n",
    "WINDOW_SECONDS = 4  # Window size in seconds\n",
    "HOP_SECONDS = 2     # Hop size\n",
    "FRAME_SIZE = int(SAMPLE_RATE * WINDOW_SECONDS) # Window size\n",
    "HOP_SIZE = int(SAMPLE_RATE * HOP_SECONDS)      # Hop size\n",
    "\n",
    "UTENTI = [p for p in range(26, 63) if p not in [32,35,37,38,45]]\n",
    "ATTIVITA = [\n",
    "    \"upstairs\", \"downstairs\", \"walk_slow\", \"walk_mod\", \"walk_fast\",\n",
    "    \"jogging\", \"standing\", \"sitting\", \"lying\"\n",
    "]\n",
    "\n",
    "# Mappa dai nomi file 'wt' ai nomi interni\n",
    "ATTIVITA_MAP_WT = {\n",
    "    \"upstairs\": \"upstairs\",\n",
    "    \"downstairs\": \"downstairs\",\n",
    "    \"walkslow\": \"walk_slow\",\n",
    "    \"walkmod\": \"walk_mod\",\n",
    "    \"walkfast\": \"walk_fast\",\n",
    "    \"jogging\": \"jogging\",\n",
    "    \"standing\": \"standing\",\n",
    "    \"sitting\": \"sitting\",\n",
    "    \"lying\": \"lying\"\n",
    "}\n",
    "ATTIVITA_WT_FILENAMES = list(ATTIVITA_MAP_WT.keys()) # Lista dei nomi file da cercare\n",
    "\n",
    "SENSORI = ['w', 't', 'wt']\n",
    "\n",
    "COLONNE_W_T = ['timestamp', 'x', 'y', 'z']\n",
    "COLONNE_WT = ['x_wrist', 'y_wrist', 'z_wrist', 'x_thigh', 'y_thigh', 'z_thigh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensor_data(base_path, participant_id, activity, sensor_type):\n",
    "    filename = f\"0{participant_id}.csv\"\n",
    "    file_path = base_path + \"/\" + sensor_type + \"/\" + activity + \"/\" + filename\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, usecols=[0, 1, 2, 3], names=COLONNE_W_T)\n",
    "        if df.isnull().values.any():\n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Errore {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wt_data(wt_path, participant_id, activity_wt_filename):\n",
    "    filename = f\"0{participant_id}_{activity_wt_filename}\"\n",
    "    file_path = os.path.join(wt_path+'/wt/', filename)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, names=COLONNE_WT)\n",
    "        if df.isnull().values.any():\n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Errore caricando {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(data, frame_size, hop_size):\n",
    "    r = np.arange(len(data))\n",
    "    s = r[::hop_size]\n",
    "\n",
    "    window_dentro = s[s + frame_size <= len(data)]\n",
    "\n",
    "    z = list(zip(window_dentro, window_dentro + frame_size))\n",
    "    g = lambda indices: data.iloc[indices[0]:indices[1]]\n",
    "\n",
    "    return pd.concat(map(g, z), keys=range(len(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc_magnitude(df, prefix=\"\"):\n",
    "    suffix = f\"_{prefix}\" if prefix else \"\"\n",
    "    x_col, y_col, z_col = f\"x{suffix}\", f\"y{suffix}\", f\"z{suffix}\"\n",
    "    output_col = f\"AccMagnitude{suffix}\"\n",
    "\n",
    "\n",
    "    if all(col in df.columns for col in [x_col, y_col, z_col]):\n",
    "        df[[x_col, y_col, z_col]] = df[[x_col, y_col, z_col]].apply(pd.to_numeric, errors='coerce')\n",
    "        df.dropna(subset=[x_col, y_col, z_col], inplace=True)\n",
    "        df[output_col] = np.sqrt(np.square(df[[x_col, y_col, z_col]]).sum(axis=1))\n",
    "    else:\n",
    "        print(f\"Colonne {x_col}, {y_col}, {z_col} non trovate in calculate_acc_magnitude.\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def calc_over_in_below_mean(df, cols, perc = 0.01):\n",
    "    result_dict = {}\n",
    "\n",
    "    df_mean = df[cols].mean()\n",
    "    df_lim_inf = df_mean - df_mean.abs() * perc\n",
    "    df_lim_sup = df_mean + df_mean.abs() * perc\n",
    "\n",
    "    for col in cols:\n",
    "        result_dict[format_colname(col, \"OverMean\")] = (df[col] > df_lim_sup[col]).sum()\n",
    "        result_dict[format_colname(col, \"InMean\")] = ((df[col] >= df_lim_inf[col]) & (df[col] <= df_lim_sup[col])).sum()\n",
    "        result_dict[format_colname(col, \"BelowMean\") ] = (df[col] < df_lim_inf[col]).sum()\n",
    "\n",
    "    return pd.DataFrame([result_dict])\n",
    "\n",
    "def calculate_energy(series):\n",
    "    fft_result = np.fft.fft(series.values)\n",
    "    power_spectrum = np.abs(fft_result)**2 / len(series)\n",
    "    return np.sum(power_spectrum)\n",
    "\n",
    "def format_colname(col, stat):\n",
    "    if \"_\" in col:\n",
    "        first, rest = col.split(\"_\", 1)\n",
    "        if len(first) == 1:\n",
    "            return f\"Acc{first.upper()}{stat}_{rest}\"\n",
    "        elif first == \"AccMagnitude\":\n",
    "            return f\"{first}{stat}_{rest}\"\n",
    "        else:\n",
    "            return f\"{first}{stat}_{rest}\"\n",
    "    else:\n",
    "        if len(col) == 1:\n",
    "            return f\"Acc{col.upper()}{stat}\"\n",
    "        elif col == \"AccMagnitude\":\n",
    "            return f\"{col}{stat}\"\n",
    "        else:\n",
    "            return f\"{col}{stat}\"\n",
    "\n",
    "def calculate_features(df, feature_cols, energy_cols):\n",
    "    df_windowed = get_frames(df, FRAME_SIZE, HOP_SIZE)\n",
    "    grouped = df_windowed.groupby(level=0)\n",
    "\n",
    "    df_mean = grouped[feature_cols].mean()\n",
    "    df_mean.columns = [format_colname(col, \"Mean\") for col in feature_cols]\n",
    "\n",
    "    df_std = grouped[feature_cols].std()\n",
    "    df_std.columns = [format_colname(col, \"Std\") for col in feature_cols]\n",
    "\n",
    "    df_min = grouped[feature_cols].min()\n",
    "    df_min.columns = [format_colname(col, \"Min\") for col in feature_cols]\n",
    "\n",
    "    df_max = grouped[feature_cols].max()\n",
    "    df_max.columns = [format_colname(col, \"Max\") for col in feature_cols]\n",
    "\n",
    "    df_oib_mean = grouped.apply(lambda x: calc_over_in_below_mean(x, feature_cols))\n",
    "    df_oib_mean = df_oib_mean.reset_index(level=1, drop=True)\n",
    "\n",
    "    energy_features_list = []\n",
    "    for col in energy_cols:\n",
    "        energy_series = grouped[col].apply(calculate_energy)\n",
    "        energy_series.name = format_colname(col, \"Energy\")\n",
    "        energy_features_list.append(energy_series)\n",
    "    df_energy = pd.concat(energy_features_list, axis=1)\n",
    "\n",
    "    all_features = pd.concat([df_mean, df_std, df_min, df_max, df_oib_mean, df_energy], axis=1)\n",
    "\n",
    "    return all_features.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "for utente in tqdm(UTENTI):\n",
    "    single_sensor_feature_list = []\n",
    "    all_sensors_feature_list = []\n",
    "    for sensore in SENSORI:\n",
    "        if sensore == 'w' or sensore == 't':\n",
    "            feature_cols_single = ['x', 'y', 'z', 'AccMagnitude']\n",
    "            energy_cols_single = ['AccMagnitude'] # Calcola energia solo sulla magnitudo\n",
    "            for attivita in ATTIVITA:\n",
    "                df = load_sensor_data(BASE_DATA_PATH, utente, attivita, sensore)\n",
    "                if df is not None and not df.empty:\n",
    "                    df = calculate_acc_magnitude(df) # Senza prefisso\n",
    "                    if 'AccMagnitude' in df.columns:\n",
    "                        df_features = calculate_features(df, feature_cols_single, energy_cols_single)\n",
    "                        df_features['Userid'] = utente\n",
    "                        df_features['Activity'] = attivita\n",
    "                        df_features['position'] = \"wrist\" if sensore == 'w' else \"thigh\"\n",
    "                        single_sensor_feature_list.append(df_features)\n",
    "\n",
    "        elif sensore == 'wt':\n",
    "            feature_cols_wt = ['x_wrist', 'y_wrist', 'z_wrist', 'x_thigh', 'y_thigh', 'z_thigh', 'AccMagnitude_wrist', 'AccMagnitude_thigh']\n",
    "            energy_cols_wt = ['AccMagnitude_wrist', 'AccMagnitude_thigh']\n",
    "            for attivita_wt in ATTIVITA_WT_FILENAMES:\n",
    "                df = load_wt_data(BASE_DATA_PATH, utente, attivita_wt)\n",
    "                if df is not None and not df.empty:\n",
    "                    df = calculate_acc_magnitude(df, prefix=\"wrist\")\n",
    "                    df = calculate_acc_magnitude(df, prefix=\"thigh\")\n",
    "                    \n",
    "                    if 'AccMagnitude_wrist' in df.columns and 'AccMagnitude_thigh' in df.columns:\n",
    "                        df_features = calculate_features(df, feature_cols_wt, energy_cols_wt)\n",
    "                        df_features['Userid'] = utente\n",
    "                        df_features['Activity'] = ATTIVITA_MAP_WT[attivita_wt]\n",
    "                        df_features['position'] = \"all sensors\"\n",
    "                        all_sensors_feature_list.append(df_features)\n",
    "\n",
    "    # Salva i dati dei sensori singoli\n",
    "    if single_sensor_feature_list:\n",
    "        df_ss_features = pd.concat(single_sensor_feature_list, ignore_index=True)\n",
    "        id_cols = ['Userid', 'Activity', 'position']\n",
    "        extracted_feature_cols = [col for col in df_ss_features.columns if col not in id_cols]\n",
    "        final_cols_ss = id_cols + extracted_feature_cols\n",
    "        df_ss_features = df_ss_features[final_cols_ss]\n",
    "        \n",
    "        output_filename_single = f\"{OUTPUT_PATH}/grouped_data_User{utente}.csv\"\n",
    "        df_ss_features.to_csv(output_filename_single, index=False)\n",
    "    else:\n",
    "        print(f\" No features {utente}.\")\n",
    "\n",
    "    # Salva i dati \"all_sensors\"\n",
    "    if all_sensors_feature_list:\n",
    "        df_as_features = pd.concat(all_sensors_feature_list, ignore_index=True)\n",
    "        id_cols = ['Userid', 'Activity', 'position'] # position qui sarÃ  sempre 'all_sensors'\n",
    "        extracted_feature_cols = [col for col in df_as_features.columns if col not in id_cols]\n",
    "        final_cols_as = id_cols + extracted_feature_cols\n",
    "        df_as_features = df_as_features[final_cols_as]\n",
    "\n",
    "        output_filename_all = f\"{OUTPUT_PATH}/grouped_data_User{utente}_combined.csv\"\n",
    "        df_as_features.to_csv(output_filename_all, index=False)\n",
    "    else:\n",
    "        print(f\" No features {utente}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
